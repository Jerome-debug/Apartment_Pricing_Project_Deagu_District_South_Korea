---
title: "Group3_Project"
author: "Bundi Kirimi"
date: "2/7/2022"
output: html_document
---


##**1.  Defining the Question**##
  

##**a) Specifying the Data Analytic Question**##



 find out the factors that influence pricing of apartments
 
 
 

##**b)  Defining the Metric for Success **##


    This project will be successful when our model reaches an Accuracy of between 75-95%
    
    

##**c)  Understanding the context**##



The dataset was acquired fro  the Deagu District in Korea.It outlines the various factors that influence the price of an Apartment.



d)Recording the Experimental Design


    Loading Libraries
    
    
    Reading the dataset
    
    Data Cleaning
    
    Exploratory Data Anlysis
    
    Feature Engineering
    
    Model Training
    
    Model Evaluation
    
    Conclusion
    
    Recommendations

##**e)  Data Relevance**##

We are using the Apartments data consisting of 30 variables: 'SalePrice', 'Age', 'Size.sqf.
', 'Floor', 'Management Type' etc.
The main variable we are interested in is the SalePrice
<!-- -->

##**2.  Loading the libraries**##

#Loading the libraries
````{r}
#specify the path where the file is located
library("data.table")
library(tidyverse)
library(magrittr)
library(warn = -1)
library("ggbiplot")
library(ggplot2)
library(lattice)
library(corrplot)
library(DataExplorer)
library(pastecs)
library(psych)
library(factoextra)
library(caret)

````


##**3.)Loading the data**##

```{r}
#Loading the data
path <-"C:/Users/Jerome/Downloads/Daegu_Real_Estate_data.csv" 

df<-read.csv(path, sep = ",")

head(df)
```





#Previewing the summary of the dataset
```{r}
summary(df)
```
The mean of Sale Price of an apartment in Deagu is 221218 whereas the median is 207964.
This suggests that the data is right_skewed/Positvely_skewed.




##**4)Checking the data**##


```{r}
#Length
length(df)
```
The dataframe has 30 columns

````{r}
#Dimensions
dim(df)

````

The dataframe has 5891 row entries and 30 columns

Column Names
```{r}
colnames(df)

```

Column data types

```{r}
sapply(df, class)
```


Our data has numerical,categorical and character variables






##**5)Data Cleaning**##



```{r}
sum(is.na(df))

```
There are no Null Values



Checking for Dupicates
```{r}
#Duplicates
duplicated_rows <- df[duplicated(df),]

dim(duplicated_rows)

```
We found 316 rows weere duplicated


Removing duplicates
```{r}
df1 <- df[-which(duplicated(df)), ]
dim(df1)
```
Our data has 5575 rows and 30 columns after removing the duplicates


Data Types
```{r}

sapply(df1, class)
```




##**6)Exploratory Data Analysis**##



#*Univariate Analysis*#

Checking the categorical variables
```{r}
#Visualizing the Hallway types
unique(df1$HallwayType)

factor(unique(df1$HallwayType))

```


```{r}
#Visualizing the Heating type
unique(df1$HeatingType)

factor(unique(df1$HeatingType))
```

```{r}
#Visualizing the Apartment Type
unique(df1$AptManageType)

factor(unique(df1$AptManageType))
```


Hallway Types


```{r}
#Visualizing the Hallway types

library(ggplot2)
ggplot(df1, aes(HallwayType)) + 
   geom_bar(fill = "red")
```

We can see most apartments have terraced Hallway types.


Apartment Management Type

```{r}
#Visualizing the Apartment Management types

library(ggplot2)
ggplot(df1, aes(AptManageType)) + 
   geom_bar(fill = "Orange")
```

Most Apartments had  Management System  by trust while very few had self management



Heating Systems



```{r}
#Visualizing the heating systems

library(ggplot2)
ggplot(df1, aes(HeatingType)) + 
   geom_bar(fill = "Blue")
```
Most Apartments had Individual Heating System while very few had central heating sytsems


Sale Price

```{r}
#
#each of the values printed below appear thrice in the dataset
#distribution
hist(df1$SalePrice , col=c("darkorange"))


```
We can witness a normal Distribution


Size in Squarefoot of The Apartments
```{r}
#Histogram of size in squarefoot
hist(df1$Size.sqf. , col=c("darkorange"))
```
We can witness a normal distribution


Floor Number
```{r}
#Histogram of floor column
#distribution
hist(df1$Floor , col=c("darkorange"))
```
The data is skewed to the right.
Thus suggests that there is very minimal buildings with so many floors compared to the ones with few floors





Creating New column Age that has the difference in years of  since the house was built and when it was sold

```{r}
df1$Age <- df1$YrSold - df1$YearBuilt



```

Adding the created Age column to our dataframe
```{r}


data <- df1[ c(1,5,6,7,8,9,10,11,14,15,16,18,19,20,21,22,23,28,29,30,31) ]

head(data)
```

Age Difference i Years
```{r}
#Distrbution of difference in years of the year built and year sold

#distribution
hist(data$Age , col=c("darkorange"))

```
The data is skewed to the right.
Most houses in the dataset were newly built




Summary

```{r}
summary(data)
````



##**Bivariate Analysis**##

Sale Price Vs Size in Square foot of the house
```{r}
#Sale Price Vs Size in Square foot of the house
ggplot(data, aes(x = Floor, y = SalePrice)) +
  geom_point() +
  stat_smooth(method = 'lm')
```
It is likely the higher the Apartment in terms of floor 
the more price of the Apartment


Apartment Management Type Vs The Sale Price
```{r}
ggplot(data, aes(x = AptManageType, y = SalePrice)) +
  geom_boxplot() 
```
The Apartments managed by Trust are more expensive to Apartments managed by Individuals.



Plot of Apartment Age vs Price
```{r}

ggplot(data, aes(x = Age, y = SalePrice)) +
  geom_point() +
  stat_smooth(method = 'lm')

```
As an Apartment Ages,the price Reduces





Plotting Size  in Squarefoot of the Apartment vs The Sale Price

```{r}

              
    #create scatterplot 

ggplot(data, aes(x = Size.sqf., y = SalePrice)) +
  geom_point() +
  stat_smooth(method = 'lm')

```
The Price of an Apartment increases with increase in Size of the Apartment

Plotting the Sale Price vs The number of Schools Nearby
```{r}
#create scatterplot of e
plot(data$SalePrice, data$N_SchoolNearBy.Total.
, pch=16, col='steelblue',
     main='SalePrice N_FacilitiesNearBy.Total.t',
     xlab='SalePrice', ylab='N_FacilitiesNearBy.Total. ')
```

There is no direct relationship between the two variables






##**Feature engineering*##

```{r}

#select list of categorical variables,df1
df2 <- data[,c(4,5,6)]#categorical
#make a subset of non-categorical variables,df2
df3 <-data[,c(1,2,3,7,8,9,10,11,15,18,19,20,21)]
```


```{r}
head(df3)
```


Dummy Encoding Categorical Variables

```{r}
dmy <- dummyVars(" ~ .", data = df2, fullRank = T)
df4 <- data.frame(predict(dmy, newdata = df2))

head(df4)
```
Joining the Categorical columns  and numerical columns 
````{r}
db <- cbind(df4,df3)
```

```{r}
head(db)
```


Checking for Dupicates
```{r}
#Duplicates
duplicated_rows <- db[duplicated(db),]

dim(duplicated_rows)

```



Removing duplicates
```{r}
df5 <- db[-which(duplicated(db)), ]
dim(df5)
```



##**Performing Normalization**##
```{r}
dummy_df2_norm <- as.data.frame(apply(df5, 2, function(x) (x -
min(x))/(max(x)-min(x))))
summary(dummy_df2_norm)
```


Correlation

```{r,fig.width=10,fig.height=10}
# Plotting the Correlation Heatmap
library(ggcorrplot)
ggcorrplot(cor(dummy_df2_norm), hc.order = F,type = 
"upper", lab = T ,
  ggtheme = ggplot2::theme_gray,
  colors = c("#00798c", "white", "#edae49"),
  tl.srt = 90)
```




##**Creating train test sets**##


```{r}
library(caret)
set.seed(387)
train_data = createDataPartition(y = dummy_df2_norm$SalePrice, p = 0.70, list = FALSE)
test_data =createDataPartition(y=dummy_df2_norm$SalePrice, p=0.30,list=FALSE)
train = dummy_df2_norm[train_data, ]
test = dummy_df2_norm[test_data, ]
```





##**Feature Selection**##




Boruta
```{r}

library(Boruta)
# Perform Boruta search
boruta_output <- Boruta(SalePrice ~ ., data=na.omit(train), doTrace=0)  

names(boruta_output)
```




```{r}
#install.packages("Boruta")
library(Boruta)


# Do a tentative rough fix
roughFixMod <- TentativeRoughFix(boruta_output)
boruta_signif <- getSelectedAttributes(roughFixMod)
print(boruta_signif)
```



```{r}
# Variable Importance Scores
imps <- attStats(roughFixMod)
imps2 = imps[imps$decision != 'Rejected', c('meanImp', 'decision')]
head(imps2[order(-imps2$meanImp), ])  # descending sort
```




```{r, fig.height=10,fig.width=10}
# Plot variable importance
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")  
```
We can see the Size in Sqft is the most imporntant variable




##**Moodel building**##



##**linear regression**##


```{r}
model = lm( SalePrice ~., data = train)
```

summary of the model
```{r}
summary(model) # Obtain coefficients, Residuals and statistics
rsquare = summary(model)$r.squared # R-squared value
```
Our model performs at 78.8%



##**Predictions**##


````{r}
library(ggplot2)
predictions = predict(model, newdata = test)
predicted.vs.original = data.frame(predicted = predictions, original = test$SalePrice)   # Create a new data frame
ggplot(predicted.vs.original, aes(x = predicted, y = original)) +
 geom_point() +
 geom_smooth(color='blue') +
 labs(x = 'Predicted Values', y = 'Original Values', title = 'Predicted vs. Original Values') +
 theme_minimal()
````
The predicted values align themselves on the line of best fit hence meaning that Model works well



##**XGBoost Model**##


```{r}
library(xgboost)

bstSparse <- xgboost(data=as.matrix(train), label = train$SalePrice, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "reg:squarederror")

```


```{r}
pred <- predict(bstSparse, newdata=as.matrix(test))

# size of the prediction vector
print(length(pred))
## [1] 1611

# limit display of predictions to the first few
print(head(pred))
```



##**Polynomial regression**##


```{r}
 poly_reg = lm(formula = SalePrice ~ .,data = train)
```



```{r}
#summary(poly_reg)
summary(poly_reg)$r.squared
```
Our  Model has an Accuracy of 78% 


```{r}

predict = predict(poly_reg, newdata = test)
predicted.vs.original = data.frame(predicted = predict, original = test$SalePrice)   # Create a new data frame
ggplot(predicted.vs.original, aes(x = predicted, y = original)) +
 geom_point() +
 geom_smooth(color='blue') +
 labs(x = 'Predicted Values', y = 'Original Values', title = 'Predicted vs. Original Values') +
 theme_minimal()
```







##**K-MEANS CLUSTERING**##


```{r}
outputk <- kmeans(dummy_df2_norm, 4)
```

```{r}
outputk$size

outputk$centers

```



##**Determining Number of clusters using Elbow Mmethod**##




```{r}

library(factoextra)
# Elbow method
fviz_nbclust(dummy_df2_norm, kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")
```
The number of clusters are 4,hence we are going to work with four clusters



##**Visualising the clusters**##



```{r}
library(factoextra)
options(repr.plot.width = 11, repr.plot.height = 10)
fviz_cluster(outputk, dummy_df2_norm)
```


##**HIERACHICAL CLUSTERING**##




```{r}

d <- dist(dummy_df2_norm, method = "euclidean")
# We then apply hierarchical clustering using the Ward's method
res.hc <- hclust(d, method = "ward.D2")
# Lastly we plot the obtained dendrogram
#--
plot(res.hc, cex = 0.6, hang = -1)

```


##**Conclusion**##



Our Models have an accuracy of 78%


We can see most apartments have terraced Hallway types.



Most Apartments had Individual Heating System while very few had central heating systems



There was a normal distribution in the sale price of apartments.


The data was skewed to the right showing that most apartments were newly built.



The Size column of the Apartments showed a normal distribution


The data is skewed to the right suggesting that there are fewer buildings located higher up than those in the lower floors


It is highly  likely that the houses located on the higher floors are more expensive than those on the lower floors. 



The apartments that were managed by trust were more expensive than those managed by individuals.




Size(sqft) is the most important factor in determining the price of an Apartment



Proximity to different facilities ie school,hospital does not really determine the price of an Apartment



##**Recommendations**##



Renovation of the old Apartments.


We integrate the individual heating system Since most Apartments preferred Individual Heating system.


We recommend Management by Trust since its mostly preferred  .


The size of an Apartment really matters as it determines the price of an Apartment.So we recommend bigger appartments


























